{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "864c8cbd-408b-47b3-88f1-3c03f0e86f85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\stefan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.2.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\stefan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.2.3)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\stefan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\stefan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\stefan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\stefan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\stefan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\stefan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (1.6.0)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\stefan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-learn) (2.2.0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\stefan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-learn) (1.14.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\stefan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\stefan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-learn) (3.5.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in c:\\users\\stefan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (3.10.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\stefan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\stefan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\stefan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\stefan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\users\\stefan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (2.2.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\stefan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\stefan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\stefan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\stefan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\stefan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: cvxopt in c:\\users\\stefan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (1.3.2)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy\n",
    "!pip install pandas\n",
    "!pip install scikit-learn\n",
    "!pip install matplotlib\n",
    "!pip install cvxopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50e0e018-c21f-40b6-acfb-ec57dcb6fabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from cvxopt import matrix, solvers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69fba52b-9535-4656-8e13-295b7f940213",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('Datasets/bank-customer-churn-prediction.csv')\n",
    "# df = pd.read_csv('Datasets/financial-risk-for-loan-approval.csv')\n",
    "# df = pd.read_csv('Datasets/loan-approval-classification-dataset.csv')\n",
    "\n",
    "# df = pd.read_csv('Datasets/campus-placement-prediction.csv')\n",
    "# df = pd.read_csv('Datasets/predict-dropout-or-academic-success.csv')\n",
    "df = pd.read_csv('Datasets/student-performance-dataset.csv')\n",
    "\n",
    "# df = pd.read_csv('Datasets/fetal-health-classifiation.csv')\n",
    "# df = pd.read_csv('Datasets/heart-disease-health-indicators-dataset.csv')\n",
    "# df = pd.read_csv('Datasets/patient-treatment-classification.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6bdfe37-7e73-4e03-b2c5-295f5db63a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix = df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4c04f2b-7631-4a02-88f5-949e2182d6c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation Matrix:\n",
      "                   StudentID       Age    Gender  Ethnicity  \\\n",
      "StudentID           1.000000 -0.042255 -0.014625  -0.012990   \n",
      "Age                -0.042255  1.000000  0.044895  -0.028473   \n",
      "Gender             -0.014625  0.044895  1.000000   0.016010   \n",
      "Ethnicity          -0.012990 -0.028473  0.016010   1.000000   \n",
      "ParentalEducation  -0.002307  0.025099  0.006771   0.033595   \n",
      "StudyTimeWeekly     0.026976 -0.006800  0.011469   0.007184   \n",
      "Absences            0.014841 -0.011511  0.021479  -0.025712   \n",
      "Tutoring           -0.007834 -0.012076 -0.031597  -0.017440   \n",
      "ParentalSupport     0.003016  0.033197  0.008065   0.020922   \n",
      "Extracurricular    -0.003611 -0.025061 -0.005964  -0.008927   \n",
      "Sports             -0.020703 -0.046320 -0.008897  -0.004484   \n",
      "Music              -0.005468 -0.003492  0.007109  -0.014627   \n",
      "Volunteering        0.008011  0.013074 -0.000200   0.013468   \n",
      "GPA                -0.002697  0.000275 -0.013360   0.027760   \n",
      "GradeClass         -0.098500 -0.006250  0.022998  -0.023326   \n",
      "\n",
      "                   ParentalEducation  StudyTimeWeekly  Absences  Tutoring  \\\n",
      "StudentID                  -0.002307         0.026976  0.014841 -0.007834   \n",
      "Age                         0.025099        -0.006800 -0.011511 -0.012076   \n",
      "Gender                      0.006771         0.011469  0.021479 -0.031597   \n",
      "Ethnicity                   0.033595         0.007184 -0.025712 -0.017440   \n",
      "ParentalEducation           1.000000        -0.011051  0.036518 -0.017340   \n",
      "StudyTimeWeekly            -0.011051         1.000000  0.009326  0.028930   \n",
      "Absences                    0.036518         0.009326  1.000000 -0.015534   \n",
      "Tutoring                   -0.017340         0.028930 -0.015534  1.000000   \n",
      "ParentalSupport            -0.017463         0.035800  0.002108 -0.000824   \n",
      "Extracurricular             0.007479        -0.022860  0.000360  0.004865   \n",
      "Sports                      0.002029         0.006836  0.041454  0.006278   \n",
      "Music                       0.039439         0.007791 -0.008692 -0.011385   \n",
      "Volunteering                0.011960        -0.016604 -0.018528 -0.050898   \n",
      "GPA                        -0.035854         0.179275 -0.919314  0.145119   \n",
      "GradeClass                  0.041031        -0.134131  0.728633 -0.111695   \n",
      "\n",
      "                   ParentalSupport  Extracurricular    Sports     Music  \\\n",
      "StudentID                 0.003016        -0.003611 -0.020703 -0.005468   \n",
      "Age                       0.033197        -0.025061 -0.046320 -0.003492   \n",
      "Gender                    0.008065        -0.005964 -0.008897  0.007109   \n",
      "Ethnicity                 0.020922        -0.008927 -0.004484 -0.014627   \n",
      "ParentalEducation        -0.017463         0.007479  0.002029  0.039439   \n",
      "StudyTimeWeekly           0.035800        -0.022860  0.006836  0.007791   \n",
      "Absences                  0.002108         0.000360  0.041454 -0.008692   \n",
      "Tutoring                 -0.000824         0.004865  0.006278 -0.011385   \n",
      "ParentalSupport           1.000000        -0.008381 -0.006176  0.035122   \n",
      "Extracurricular          -0.008381         1.000000 -0.011820 -0.014191   \n",
      "Sports                   -0.006176        -0.011820  1.000000 -0.020474   \n",
      "Music                     0.035122        -0.014191 -0.020474  1.000000   \n",
      "Volunteering             -0.006036        -0.007427 -0.002799  0.017224   \n",
      "GPA                       0.190774         0.094078  0.057859  0.073318   \n",
      "GradeClass               -0.136823        -0.069733 -0.026654 -0.036065   \n",
      "\n",
      "                   Volunteering       GPA  GradeClass  \n",
      "StudentID              0.008011 -0.002697   -0.098500  \n",
      "Age                    0.013074  0.000275   -0.006250  \n",
      "Gender                -0.000200 -0.013360    0.022998  \n",
      "Ethnicity              0.013468  0.027760   -0.023326  \n",
      "ParentalEducation      0.011960 -0.035854    0.041031  \n",
      "StudyTimeWeekly       -0.016604  0.179275   -0.134131  \n",
      "Absences              -0.018528 -0.919314    0.728633  \n",
      "Tutoring              -0.050898  0.145119   -0.111695  \n",
      "ParentalSupport       -0.006036  0.190774   -0.136823  \n",
      "Extracurricular       -0.007427  0.094078   -0.069733  \n",
      "Sports                -0.002799  0.057859   -0.026654  \n",
      "Music                  0.017224  0.073318   -0.036065  \n",
      "Volunteering           1.000000  0.003258    0.013156  \n",
      "GPA                    0.003258  1.000000   -0.782835  \n",
      "GradeClass             0.013156 -0.782835    1.000000  \n"
     ]
    }
   ],
   "source": [
    "print(\"Correlation Matrix:\")\n",
    "print(correlation_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f713a932-4506-4f56-b632-0aa3c822be7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DBSCAN:\n",
    "    def __init__(self, eps=1.0, minPts=5, equation='euclidean'):\n",
    "        self.eps = eps # Radius for neighbourhood search\n",
    "        self.minPts = minPts # Minimum number of points to form a cluster\n",
    "        self.equation = equation\n",
    "        \n",
    "    def fit(self, dataframe):\n",
    "        # Initialise labels array with -1\n",
    "        self.labels = np.zeros(len(dataframe), dtype=int) - 1\n",
    "        self.clusters = [] # List to hold all clusters\n",
    "        cidx = 0 # Cluster ID counter\n",
    "        for x in range(len(dataframe)):\n",
    "            if self.labels[x] == -1:\n",
    "                neighbours = self.get_neighbours(dataframe, x)\n",
    "                if len(neighbours) < self.minPts:\n",
    "                    self.labels[x] = 0 # Mark point as anomaly\n",
    "                else:\n",
    "                    cidx += 1\n",
    "                    self.clusters.append([x])\n",
    "                    self.labels[x] = cidx # Assign cluster ID to the point\n",
    "\n",
    "                    # Exapnd the cluster with points\n",
    "                    for y in neighbours:\n",
    "                        if self.labels[y] == -1:\n",
    "                            self.labels[y] = cidx\n",
    "                            self.clusters[cidx-1].append(y)\n",
    "                            neighbours2 = self.get_neighbours(dataframe, y)\n",
    "                            if len(neighbours2) >= self.minPts:\n",
    "                                neighbours += list(set(neighbours2) - set(neighbours))\n",
    "                        elif self.labels[y] == 0:\n",
    "                            self.labels[y] = cidx\n",
    "                            self.clusters[cidx-1].append(y)\n",
    "        return self.clusters\n",
    "\n",
    "    def get_neighbours(self, dataframe, x):\n",
    "        neighbours = set()\n",
    "        # Iterate over all points to calculate distances\n",
    "        for y in range(len(dataframe)):\n",
    "            if self.distance(dataframe[x], dataframe[y]) <= self.eps: # Check if within eps distance\n",
    "                neighbours.add(y)\n",
    "        return list(neighbours)\n",
    "    \n",
    "    def distance(self, x, y):\n",
    "        # Euclidean distance\n",
    "        return np.sqrt(np.sum((x-y)**2))\n",
    "                           \n",
    "\n",
    "    def plot(self, data):\n",
    "        # Create a 3D plot\n",
    "        figure = plt.figure(figsize=(10, 8))\n",
    "        ax = figure.add_subplot(111, projection='3d')\n",
    "\n",
    "        # Find noise points and clusters\n",
    "        noise_idx = np.where(self.labels == 0)[0]\n",
    "        cluster_idxs = [np.array(c) for c in self.clusters]\n",
    "\n",
    "        # Assign colours to clusters\n",
    "        colours = cm.rainbow(np.linspace(0, 1, len(self.clusters) + 1))\n",
    "\n",
    "        # Plot each cluster\n",
    "        for i, cluster_idx in enumerate(cluster_idxs):\n",
    "            ax.scatter(data[cluster_idx, 0], data[cluster_idx, 1], data[cluster_idx, 2], \n",
    "                       color=colours[i], s=10, label=f'Cluster {i + 1}')\n",
    "\n",
    "        # Plot anomalies\n",
    "        if len(noise_idx) > 0:\n",
    "            ax.scatter(data[noise_idx, 0], data[noise_idx, 1], data[noise_idx, 2], \n",
    "                       color='black', s=10, label='Anomalies')\n",
    "\n",
    "        # Add labels and legend\n",
    "        ax.set_title(\"3D DBSCAN Clustering\")\n",
    "        ax.set_xlabel(\"Feature 1\")\n",
    "        ax.set_ylabel(\"Feature 2\")\n",
    "        ax.set_zlabel(\"Feature 3\")\n",
    "        ax.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc49093a-33fc-4ed9-8cc0-6212c1b8a2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OCSVM:\n",
    "    def __init__(self, nu=0.1, kernel='rbf', gamma=1.0):\n",
    "        self.nu = nu\n",
    "        self.kernel = kernel\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def _kernel_function(self, X, Y=None):\n",
    "        # Computer the kernel matrix\n",
    "        if Y is None:\n",
    "            Y = X\n",
    "        if self.kernel == 'rbf':\n",
    "            # Radial basis function\n",
    "            sq_dist = np.sum(X**2, axis=1).reshape(-1, 1) + np.sum(Y**2, axis=1) - 2 * np.dot(X, Y.T)\n",
    "            return np.exp(-self.gamma * sq_dist)\n",
    "        elif self.kernel == 'linear':\n",
    "            # Linear kernel\n",
    "            return np.dot(X, Y.T)\n",
    "        elif self.kernel == 'poly':\n",
    "            # Polynomial kernel\n",
    "            return (np.dot(X, Y.T) + 1) ** 3\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported kernel type\")\n",
    "\n",
    "    def fit(self, X):\n",
    "        n_samples = X.shape[0]\n",
    "        K = self._kernel_function(X)\n",
    "\n",
    "        # Define the quadratic programming problem\n",
    "        P = matrix(K)\n",
    "        q = matrix(-np.ones((n_samples, 1)))\n",
    "        \n",
    "        G = matrix(np.vstack((-np.eye(n_samples), np.eye(n_samples))))\n",
    "        h = matrix(np.hstack((np.zeros(n_samples), np.ones(n_samples) / (self.nu * n_samples))))\n",
    "        \n",
    "        A = matrix(1.0, (1, n_samples)) # Equaltiy constraint\n",
    "        b = matrix(1.0)\n",
    "\n",
    "        # Solve quadratic programming problem\n",
    "        sol = solvers.qp(P, q, G, h, A, b)\n",
    "\n",
    "        # Extract Lagrange multipliers (alphas)\n",
    "        alphas = np.array(sol['x']).flatten()\n",
    "        support_vector_indices = alphas > 1e-5\n",
    "        self.alphas = alphas[support_vector_indices]\n",
    "        self.support_vectors = X[support_vector_indices]\n",
    "        self.K_sv = K[support_vector_indices][:, support_vector_indices]\n",
    "        \n",
    "        # Compute the intercept term\n",
    "        self.rho = np.mean(self.K_sv @ self.alphas)\n",
    "\n",
    "    def decision_function(self, X):\n",
    "        # Compute the decision function\n",
    "        K_test = self._kernel_function(X, self.support_vectors)\n",
    "        return np.sum(K_test * self.alphas, axis=1) - self.rho\n",
    "\n",
    "    def predict(self, X):\n",
    "        # Predict whether the data is an inlier or an outlier\n",
    "        return np.sign(self.decision_function(X))\n",
    "    \n",
    "    \n",
    "    def plot(self, X, predictions, feature_names=None):\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X.values\n",
    "\n",
    "        # Assign colors for anomalies and inliers\n",
    "        colors = np.array(['blue' if p == 1 else 'red' for p in predictions])\n",
    "        plt.figure(figsize=(10, 6))\n",
    "\n",
    "        if X.shape[1] == 2:  # If data has 2 features\n",
    "            plt.scatter(X[:, 0], X[:, 1], c=colors, edgecolor='k', alpha=0.8)\n",
    "            plt.xlabel(feature_names[0] if feature_names else 'Feature 1')\n",
    "            plt.ylabel(feature_names[1] if feature_names else 'Feature 2')\n",
    "        else:  # For more than 2 features, plot only the first two\n",
    "            plt.scatter(X[:, 0], X[:, 1], c=colors, edgecolor='k', alpha=0.8)\n",
    "            plt.xlabel('Feature 1')\n",
    "            plt.ylabel('Feature 2')\n",
    "        plt.title('Isolation Forest - Anomaly Detection')\n",
    "        plt.legend(handles=[plt.Line2D([0], [0], marker='o', color='w', markerfacecolor='blue', markersize=10, label='Inliers'),\n",
    "                            plt.Line2D([0], [0], marker='o', color='w', markerfacecolor='red', markersize=10, label='Anomalies')],\n",
    "                   loc='upper right')\n",
    "        plt.grid()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7037c01f-5283-4782-9807-aa8c4f817ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IsolationTree:\n",
    "    def __init__(self, max_depth):\n",
    "        self.max_depth = max_depth\n",
    "        self.split_feature = None\n",
    "        self.split_value = None\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "        self.is_terminal = False\n",
    "        self.size = 0\n",
    "\n",
    "    def fit(self, X, depth=0):\n",
    "        # Check the termination condition\n",
    "        if depth >= self.max_depth or len(X) <= 1:\n",
    "            self.is_terminal = True\n",
    "            self.size = len(X)\n",
    "            return\n",
    "\n",
    "        # Randomly choose a feature and split value\n",
    "        num_features = X.shape[1]\n",
    "        self.split_feature = np.random.randint(0, num_features)\n",
    "        min_val, max_val = np.min(X[:, self.split_feature]), np.max(X[:, self.split_feature])\n",
    "\n",
    "        if min_val == max_val:  # No meaningful split\n",
    "            self.is_terminal = True\n",
    "            self.size = len(X)\n",
    "            return\n",
    "\n",
    "        self.split_value = np.random.uniform(min_val, max_val)\n",
    "\n",
    "        # Partition the data\n",
    "        left_mask = X[:, self.split_feature] < self.split_value # Mask for left subset\n",
    "        right_mask = ~left_mask # Mask for right subset\n",
    "\n",
    "        self.left = IsolationTree(self.max_depth)\n",
    "        self.right = IsolationTree(self.max_depth)\n",
    "\n",
    "        self.left.fit(X[left_mask], depth + 1)\n",
    "        self.right.fit(X[right_mask], depth + 1)\n",
    "\n",
    "    def path_length(self, X):\n",
    "        path_lengths = np.zeros(X.shape[0])\n",
    "\n",
    "        for i, x in enumerate(X):\n",
    "            node = self\n",
    "            depth = 0\n",
    "            while not node.is_terminal: # Traverse tree until termianl node reached\n",
    "                if x[node.split_feature] < node.split_value:\n",
    "                    node = node.left\n",
    "                else:\n",
    "                    node = node.right\n",
    "                depth += 1\n",
    "            path_lengths[i] = depth + self._c(node.size)\n",
    "        return path_lengths\n",
    "\n",
    "    @staticmethod\n",
    "    def _c(size):\n",
    "        # Calculate average path length of a binary tree for given size\n",
    "        if size <= 1:\n",
    "            return 0\n",
    "        return 2 * (np.log(size - 1) + 0.5772156649) - (2 * (size - 1) / size)\n",
    "\n",
    "\n",
    "class IForest:\n",
    "    def __init__(self, n_estimators=100, max_samples=256, max_depth=None):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.max_samples = max_samples\n",
    "        self.max_depth = max_depth\n",
    "        self.forest = []\n",
    "\n",
    "    def fit(self, X):\n",
    "        # Convert DataFrame to NumPy array if needed\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X.values\n",
    "\n",
    "        n_samples, num_features = X.shape\n",
    "        self.max_samples = min(self.max_samples, num_samples)\n",
    "        if self.max_depth is None:\n",
    "            self.max_depth = int(np.ceil(np.log2(self.max_samples)))\n",
    "\n",
    "        self.forest = []\n",
    "        for _ in range(self.n_estimators):\n",
    "            sample_indices = np.random.choice(num_samples, self.max_samples, replace=False)\n",
    "            X_sample = X[sample_indices]\n",
    "            tree = IsolationTree(self.max_depth)\n",
    "            tree.fit(X_sample)\n",
    "            self.forest.append(tree)\n",
    "\n",
    "    def anomaly_score(self, X):\n",
    "        # Convert DataFrame to NumPy array if needed\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X.values\n",
    "\n",
    "        path_lengths = np.zeros(X.shape[0])\n",
    "        for tree in self.forest:\n",
    "            path_lengths += tree.path_length(X)\n",
    "        path_lengths /= len(self.forest)\n",
    "\n",
    "        # Compute anomaly score based on path lengths\n",
    "        c_n = 2 * (np.log(self.max_samples - 1) + 0.5772156649) - (2 * (self.max_samples - 1) / self.max_samples)\n",
    "        scores = 2 ** (-path_lengths / c_n)\n",
    "        return scores\n",
    "\n",
    "    def predict(self, X, threshold=0.5):\n",
    "        scores = self.anomaly_score(X)\n",
    "        return np.where(scores > threshold, -1, 1)  # -1 for anomalies, 1 for normal\n",
    "\n",
    "    def plot(self, X, predictions, feature_names=None):\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X.values\n",
    "\n",
    "        # Assign colors for anomalies and inliers\n",
    "        colors = np.array(['blue' if p == 1 else 'red' for p in predictions])\n",
    "        plt.figure(figsize=(10, 6))\n",
    "\n",
    "        if X.shape[1] == 2:  # If data has 2 features\n",
    "            plt.scatter(X[:, 0], X[:, 1], c=colors, alpha=0.8)\n",
    "            plt.xlabel(feature_names[0])\n",
    "            plt.ylabel(feature_names[1])\n",
    "        else:  # For more than 2 features, plot only the first two\n",
    "            plt.scatter(X[:, 0], X[:, 1], c=colors, alpha=0.8)\n",
    "            plt.xlabel('Feature 1')\n",
    "            plt.ylabel('Feature 2')\n",
    "        plt.title('Isolation Forest - Anomaly Detection')\n",
    "        plt.legend(handles=[plt.Line2D([0], [0], marker='o', color='w', markerfacecolor='blue', markersize=10, label='Inliers'),\n",
    "                            plt.Line2D([0], [0], marker='o', color='w', markerfacecolor='red', markersize=10, label='Anomalies')],\n",
    "                   loc='upper right')\n",
    "        plt.grid()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f22cf84c-4c0c-4ffc-adfd-a7adb1f3fcad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['StudentID', 'StudyTimeWeekly', 'Absences', 'GPA']\n"
     ]
    }
   ],
   "source": [
    "used_cols = [col for col in df.columns if df[col].nunique() > 25]\n",
    "print(used_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8d01d7e0-ec41-4ea2-8d9e-3c9ad27f1377",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique ID column(s): ['StudentID']\n"
     ]
    }
   ],
   "source": [
    "continuous_ratio_threshold = 2  # Customize based on the dataset characteristics\n",
    "\n",
    "# Function to identify unique ID column\n",
    "def identify_unique_id(df):\n",
    "    unique_id_columns = []\n",
    "    for col in df.columns:\n",
    "        if (\n",
    "            df[col].nunique() == len(df)  # Unique values equal to the number of rows\n",
    "            and not pd.api.types.is_float_dtype(df[col])  # Exclude float columns\n",
    "        ):\n",
    "            # Calculate range-to-unique ratio for integer columns\n",
    "            if pd.api.types.is_integer_dtype(df[col]):\n",
    "                col_range = df[col].max() - df[col].min() + 1\n",
    "                if col_range / df[col].nunique() > continuous_ratio_threshold:\n",
    "                    continue  # Likely a continuous integer column, not an ID\n",
    "            unique_id_columns.append(col)\n",
    "    return unique_id_columns\n",
    "\n",
    "# Identify the unique ID column\n",
    "unique_id_columns = identify_unique_id(df)\n",
    "\n",
    "print(\"Unique ID column(s):\", unique_id_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfda9f7e-a0ba-4686-b283-2e5efb3d8995",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['column_name'], inplace=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
