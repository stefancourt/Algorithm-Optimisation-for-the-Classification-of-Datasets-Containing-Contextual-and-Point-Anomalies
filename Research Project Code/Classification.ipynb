{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91543603-d520-4f29-8461-549e53f592ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run Algorithms.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "365f21a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e9691a2-0519-4358-b0ca-303fed69529a",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {\n",
    "    'education_2_df': 'Datasets/predict-dropout-or-academic-success.csv'\n",
    "}\n",
    "anomalous_datasets = {\n",
    "    'a_education_2_df': 'Datasets/predict-dropout-or-academic-success_anomaly.csv'\n",
    "}\n",
    "\n",
    "\n",
    "finance_1_df = pd.read_csv('Datasets/bank-customer-churn-prediction.csv')\n",
    "finance_2_df = pd.read_csv('Datasets/financial-risk-for-loan-approval.csv')\n",
    "finance_3_df = pd.read_csv('Datasets/loan-approval-classification-dataset.csv')\n",
    "\n",
    "education_1_df = pd.read_csv('Datasets/campus-placement-prediction.csv')\n",
    "education_2_df = pd.read_csv('Datasets/predict-dropout-or-academic-success.csv')\n",
    "education_3_df = pd.read_csv('Datasets/student-performance-dataset.csv')\n",
    "\n",
    "health_1_df = pd.read_csv('Datasets/fetal-health-classifiation.csv')\n",
    "health_2_df = pd.read_csv('Datasets/heart-disease-health-indicators-dataset.csv')\n",
    "health_3_df = pd.read_csv('Datasets/patient-treatment-classification.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c231e4f5-ab1e-4597-bb0f-1cd48af4f323",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['HAEMATOCRIT', 'HAEMOGLOBINS', 'ERYTHROCYTE', 'LEUCOCYTE', 'THROMBOCYTE', 'MCH', 'MCHC', 'MCV', 'AGE']\n"
     ]
    }
   ],
   "source": [
    "for df_name, file_path in datasets.items():\n",
    "    df = pd.read_csv(file_path)\n",
    "    used_cols = [col for col in df.columns if df[col].nunique() > 50]\n",
    "    print(used_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "89cc7958-f201-476f-b283-080c1c3426cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(dataframe: pd.DataFrame, filename: str) -> None:\n",
    "    # Drop rows with missing values\n",
    "    total_shape = dataframe.shape[0]\n",
    "    print(total_shape)\n",
    "\n",
    "    dropped_indices = [(index, col) for index, row in dataframe.iterrows() for col in dataframe.columns if pd.isna(row[col])]\n",
    "\n",
    "    \n",
    "    dataframe = dataframe.dropna()\n",
    "\n",
    "    # Features and target\n",
    "    if filename in ['Datasets/campus-placement-prediction.csv', 'Datasets/campus-placement-prediction_anomaly.csv']:\n",
    "        X = dataframe.drop(columns=['status'])\n",
    "        y = dataframe['status']\n",
    "    elif filename in ['Datasets/predict-dropout-or-academic-success.csv', 'Datasets/predict-dropout-or-academic-success_anomaly.csv']:\n",
    "        X = dataframe.drop(columns=['Target'])\n",
    "        y = dataframe['Target']\n",
    "    elif filename in ['Datasets/student-performance-dataset.csv', 'Datasets/student-performance-dataset_anomaly.csv']:\n",
    "        X = dataframe.drop(columns=['GradeClass'])\n",
    "        y = dataframe['GradeClass']\n",
    "    elif filename in ['Datasets/bank-customer-churn-prediction.csv', 'Datasets/bank-customer-churn-prediction_anomaly.csv']:\n",
    "        X = dataframe.drop(columns=['churn'])\n",
    "        y = dataframe['churn']\n",
    "    elif filename in ['Datasets/financial-risk-for-loan-approval.csv', 'Datasets/financial-risk-for-loan-approval_anomaly.csv']:\n",
    "        X = dataframe.drop(columns=['LoanApproved'])\n",
    "        y = dataframe['LoanApproved']\n",
    "    elif filename in ['Datasets/loan-approval-classification-dataset.csv', 'Datasets/loan-approval-classification-dataset_anomaly.csv']:\n",
    "        X = dataframe.drop(columns=['loan_status'])\n",
    "        y = dataframe['loan_status']\n",
    "    elif filename in ['Datasets/fetal-health-classifiation.csv', 'Datasets/fetal-health-classifiation_anomaly.csv']:\n",
    "        X = dataframe.drop(columns=['fetal_health'])\n",
    "        y = dataframe['fetal_health']\n",
    "    elif filename in ['Datasets/heart-disease-health-indicators-dataset.csv', 'Datasets/heart-disease-health-indicators-dataset_anomaly.csv']:\n",
    "        X = dataframe.drop(columns=['HeartDiseaseorAttack'])\n",
    "        y = dataframe['HeartDiseaseorAttack']\n",
    "    elif filename in ['Datasets/patient-treatment-classification.csv', 'Datasets/patient-treatment-classification_anomaly.csv']:\n",
    "        X = dataframe.drop(columns=['SOURCE'])\n",
    "        y = dataframe['SOURCE']\n",
    "    \n",
    "    # Train-test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    print(f\"Dataset: {filename}\")\n",
    "    print(f\"Shape after dropping missing values: {dataframe.shape}\")\n",
    "    print(f\"Test set size: {X_train.shape}\")\n",
    "    \n",
    "    # Initialize and train RandomForestClassifier\n",
    "    rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    rf_classifier.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on test data\n",
    "    y_pred = rf_classifier.predict(X_test)\n",
    "    \n",
    "    # Evaluate performance\n",
    "    current_shape = dataframe.shape[0]\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    accuracy_whole = accuracy * (current_shape / total_shape)\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"Accuracy Whole:\", accuracy_whole)\n",
    "    return dropped_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6e5d05c0-ce1e-4bf4-b50c-05f15762c5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_graph(dataframe: pd.DataFrame, filename: str) -> None:\n",
    "    # Features and target\n",
    "    if filename in ['Datasets/campus-placement-prediction.csv', 'Datasets/campus-placement-prediction_anomaly.csv']:\n",
    "        X = dataframe.drop(columns=['status'])\n",
    "        y = dataframe['status']\n",
    "    elif filename in ['Datasets/predict-dropout-or-academic-success.csv', 'Datasets/predict-dropout-or-academic-success_anomaly.csv']:\n",
    "        X = dataframe.drop(columns=['Target'])\n",
    "        y = dataframe['Target']\n",
    "    elif filename in ['Datasets/student-performance-dataset.csv', 'Datasets/student-performance-dataset_anomaly.csv']:\n",
    "        X = dataframe.drop(columns=['GradeClass'])\n",
    "        y = dataframe['GradeClass']\n",
    "    elif filename in ['Datasets/bank-customer-churn-prediction.csv', 'Datasets/bank-customer-churn-prediction_anomaly.csv']:\n",
    "        X = dataframe.drop(columns=['churn'])\n",
    "        y = dataframe['churn']\n",
    "    elif filename in ['Datasets/financial-risk-for-loan-approval.csv', 'Datasets/financial-risk-for-loan-approval_anomaly.csv']:\n",
    "        X = dataframe.drop(columns=['LoanApproved'])\n",
    "        y = dataframe['LoanApproved']\n",
    "    elif filename in ['Datasets/loan-approval-classification-dataset.csv', 'Datasets/loan-approval-classification-dataset_anomaly.csv']:\n",
    "        X = dataframe.drop(columns=['loan_status'])\n",
    "        y = dataframe['loan_status']\n",
    "    elif filename in ['Datasets/fetal-health-classifiation.csv', 'Datasets/fetal-health-classifiation_anomaly.csv']:\n",
    "        X = dataframe.drop(columns=['fetal_health'])\n",
    "        y = dataframe['fetal_health']\n",
    "    elif filename in ['Datasets/heart-disease-health-indicators-dataset.csv', 'Datasets/heart-disease-health-indicators-dataset_anomaly.csv']:\n",
    "        X = dataframe.drop(columns=['HeartDiseaseorAttack'])\n",
    "        y = dataframe['HeartDiseaseorAttack']\n",
    "    elif filename in ['Datasets/patient-treatment-classification.csv', 'Datasets/patient-treatment-classification_anomaly.csv']:\n",
    "        X = dataframe.drop(columns=['SOURCE'])\n",
    "        y = dataframe['SOURCE']\n",
    "    \n",
    "        \n",
    "    \n",
    "    # Train-test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Initialize and train RandomForestRegressor\n",
    "    rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    rf_classifier.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on test data\n",
    "    y_pred = rf_classifier.predict(X_test)\n",
    "    \n",
    "    # Evaluate performance\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "    print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "    \n",
    "    feature_importances = rf_classifier.feature_importances_\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.bar(X.columns, feature_importances)\n",
    "    plt.xlabel('Features')\n",
    "    plt.ylabel('Importance')\n",
    "    plt.title('Feature Importance')\n",
    "    plt.xticks(rotation=90)  # Rotate labels 90 degrees (vertical)\n",
    "    \n",
    "    # Display the plot\n",
    "    plt.tight_layout() \n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3f397895-6c32-44d5-a510-d3aaee839f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_datasets() -> None:\n",
    "    for df_name, file_path in datasets.items():\n",
    "        df = pd.read_csv(file_path)\n",
    "        df = preprocessing(df, file_path)\n",
    "        classify(df, file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5d465555-58c1-41b7-b4b2-641747042074",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_anomalous() -> None:\n",
    "    total_list = []\n",
    "    for df_name, file_path in anomalous_datasets.items():\n",
    "        df = pd.read_csv(file_path)\n",
    "        df = preprocessing(df, file_path)\n",
    "        x = classify(df, file_path)\n",
    "        total_list.append(x)\n",
    "    return total_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "20bcbb2f-50df-4113-a99e-3e4d154c5b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_dbscan(eps) -> None:\n",
    "    start_time = time.time()\n",
    "    \n",
    "    for df_name, file_path in anomalous_datasets.items():\n",
    "        df = pd.read_csv(file_path)\n",
    "        # Already have been preprocessed\n",
    "        df = drop_DBSCAN(df, file_path, eps)\n",
    "        classify(df, file_path)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    \n",
    "    print(f\"Total time taken: {elapsed_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b490305a-9186-4f5c-86a5-6314f3064fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_ocsvm(nu, gamma) -> None:\n",
    "    start_time = time.time()\n",
    "    \n",
    "    for df_name, file_path in anomalous_datasets.items():\n",
    "        df = pd.read_csv(file_path)\n",
    "        # Already have been preprocessed\n",
    "        df = drop_OCSVM(df, file_path, nu, gamma)\n",
    "        classify(df, file_path)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    \n",
    "    print(f\"Total time taken: {elapsed_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "93bdc1f0-fafe-4e87-bb7e-d9c76cb96101",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_isolation_forest(threshold: float) -> None:\n",
    "    start_time = time.time()\n",
    "    \n",
    "    for df_name, file_path in anomalous_datasets.items():\n",
    "        df = pd.read_csv(file_path)\n",
    "        # Already have been preprocessed\n",
    "        df = drop_IF(df, file_path, threshold)\n",
    "        classify(df, file_path)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    \n",
    "    print(f\"Total time taken: {elapsed_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e034c5d1-e803-4f0a-a483-b73db9d6d55e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272e0b54-0c20-4b53-a924-8db0d1199b2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e7b87c-bcfa-45ca-bedd-e5a61399534d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "virtual env",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
